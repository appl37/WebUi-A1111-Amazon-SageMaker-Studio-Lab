{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Run This Command In Terminal\n",
        "\n"
      ],
      "metadata": {
        "id": "vxYteB9nSX3-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conda create --name py310env python=3.10 -y\n",
        "conda activate py310env\n",
        "pip install ipykernel\n",
        "python -m ipykernel install --user --name py310env --display-name \"Python 3.10 (py310env)\"\n",
        "conda install -c conda-forge libglib -y\n",
        "conda update -n base conda -y"
      ],
      "metadata": {
        "id": "0zSHvnVKTTXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Python dependencies!!!"
      ],
      "metadata": {
        "id": "76xxmC9HKdms"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "#Conda installation for PyGObject with automatic \"yes\" confirmation\n",
        "!conda install -c conda-forge pygobject -y\n",
        "\n",
        "# Pip installation for OpenCV and other packages (no need for -y with pip)\n",
        "!pip install opencv-python\n",
        "!pip install opencv-contrib-python\n",
        "\n",
        "clear_output()\n",
        "print('\u001b[1;32mDone!')"
      ],
      "metadata": {
        "id": "fvI5o4AcLJzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stable-diffusion dependencies!!!!!"
      ],
      "metadata": {
        "id": "lzzY6lQRKxRt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "# aria2 for parallel downloads, along with other libraries\n",
        "!conda install -y -c conda-forge libglib ffmpeg aria2\n",
        "# Install diffusers and other dependencies using pip\n",
        "!pip install diffusers transformers accelerate scipy safetensors\n",
        "!pip install torch torchvision --upgrade\n",
        "!pip install xformers\n",
        "!pip install insightface\n",
        "\n",
        "clear_output()\n",
        "print('\u001b[1;32mDone!')\n",
        "!rm -rf /home/studio-lab-user/.cache\n",
        "!df -h | grep -E 'Avail|home'\n",
        "\n",
        "print('\u001b[1;32mDone!')"
      ],
      "metadata": {
        "id": "DF02frn4LECk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stable-Diffusion Cloning"
      ],
      "metadata": {
        "id": "eyQ0usVMNKj8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git\n",
        "\n",
        "from IPython.display import clear_output\n",
        "\n",
        "%cd ~/stable-diffusion-webui\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "%cd ~/home/studio-lab-user\n",
        "\n",
        "clear_output()\n",
        "print('\u001b[1;32mDone!')"
      ],
      "metadata": {
        "id": "hkMkMdq0NTOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models or Checkpoint\n"
      ],
      "metadata": {
        "id": "D3FPHTicN93T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import time\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "# Download path\n",
        "download_path = \"/home/studio-lab-user/stable-diffusion-webui/models/Stable-diffusion/\"\n",
        "\n",
        "# Ensure the download path exists, create it if it doesn't\n",
        "os.makedirs(download_path, exist_ok=True)\n",
        "\n",
        "# Helper function to convert bytes into human-readable format\n",
        "def format_size(size):\n",
        "    for unit in ['B', 'KB', 'MB', 'GB', 'TB']:\n",
        "        if size < 1024:\n",
        "            return f\"{size:.2f} {unit}\"\n",
        "        size /= 1024\n",
        "\n",
        "# Function to check available storage space\n",
        "def check_storage_space():\n",
        "    result = subprocess.run([\"df\", \"-h\", \"--output=avail,target\"], capture_output=True, text=True)\n",
        "    lines = result.stdout.splitlines()\n",
        "\n",
        "    for line in lines:\n",
        "        if '/home' in line:\n",
        "            available_space = line.split()[0]  # Get available space value\n",
        "            return available_space\n",
        "    return \"0M\"  # Default value if no storage info available\n",
        "\n",
        "# Function to download model with reduced output frequency\n",
        "def download_model(url, filename, headers):\n",
        "    try:\n",
        "        # Automatically handle the file extension based on the filename provided\n",
        "        response = requests.get(url, headers=headers, stream=True)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            total_size = int(response.headers.get('content-length', 0))\n",
        "            downloaded_size = 0\n",
        "            start_time = time.time()\n",
        "\n",
        "            with open(filename, 'wb') as file:\n",
        "                chunk_size = 1024 * 1024  # Reduce the chunk size\n",
        "                for chunk in response.iter_content(chunk_size=chunk_size):\n",
        "                    if chunk:\n",
        "                        try:\n",
        "                            file.write(chunk)\n",
        "                            downloaded_size += len(chunk)\n",
        "\n",
        "                            if downloaded_size >= 10 * 1024 * 1024:  # Log progress every 10 MB\n",
        "                                elapsed_time = time.time() - start_time\n",
        "                                speed = (downloaded_size / (1024 * 1024)) / elapsed_time\n",
        "                                print(f\"Downloaded {format_size(downloaded_size)} of {format_size(total_size)} at {speed:.2f} MB/s\", end='\\r')\n",
        "                        except OSError as e:\n",
        "                            if \"No space left on device\" in str(e):\n",
        "                                print(f\"\\n\\nError: No space left on device while downloading {filename}.\")\n",
        "                                return \"no_space\"  # Return a specific message if no space\n",
        "                            raise\n",
        "            print(f\"\\n\\nDownloaded {filename} successfully!\\n\")\n",
        "            return \"success\"\n",
        "        else:\n",
        "            print(f\"\\n\\nFailed to download {filename}. Status code: {response.status_code}, Message: {response.text}\\n\")\n",
        "            return \"error\"\n",
        "    except Exception as e:\n",
        "        print(f\"\\n\\nError during download of {filename}: {e}\\n\")\n",
        "        if \"data exceeds\" in str(e).lower():\n",
        "            print(\"Error: Data exceeds Jupyter memory limit. Please download outside Jupyter Lab.\\n\")\n",
        "        return \"error\"\n",
        "\n",
        "# Combined function to handle both Hugging Face and CivitAI links\n",
        "def download_models(model_list, huggingface_headers, civitai_headers):\n",
        "    for model in model_list:\n",
        "        if model[\"enabled\"]:\n",
        "            url = model[\"link\"]\n",
        "            filename = os.path.join(download_path, model[\"filename\"])\n",
        "\n",
        "            # Identify if it's Hugging Face or CivitAI by checking the URL structure\n",
        "            if \"huggingface.co\" in url:\n",
        "                headers = huggingface_headers\n",
        "                platform = \"Hugging Face\"\n",
        "            elif \"civitai.com\" in url:\n",
        "                headers = civitai_headers\n",
        "                platform = \"CivitAI\"\n",
        "            else:\n",
        "                print(f\"\\n\\nUnknown platform for {filename}. Skipping...\\n\")\n",
        "                continue\n",
        "\n",
        "            print(f\"\\nStarting download from {platform} for {filename}...\\n\")\n",
        "\n",
        "            # Check storage before downloading\n",
        "            available_space = check_storage_space()\n",
        "            print(f\"Available space before downloading: {available_space}\\n\")\n",
        "\n",
        "            if available_space.endswith('G') or available_space.endswith('M'):\n",
        "                result = download_model(url, filename, headers)\n",
        "                if result == \"no_space\":\n",
        "                    print(f\"\\n\\nNo space available. Stopping remaining downloads.\\n\")\n",
        "                    break\n",
        "            else:\n",
        "                print(f\"\\n\\nNo space available for {filename}. Skipping...\\n\")\n",
        "        else:\n",
        "            print(f\"\\n\\nSkipping {model['filename']} (Disabled)\\n\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ----------------------------------------\n",
        "# Example combined model inputs (both Hugging Face and CivitAI)\n",
        "model_list = [\n",
        "\n",
        "    {\"link\": \"https://huggingface.co/ckpt/CyberRealistic/resolve/main/cyberrealistic_v32.safetensors?download=true\",\n",
        "     \"filename\": \"Cyberrealistic.safetensors\",     \"enabled\": True  },\n",
        "\n",
        "    {\"link\": \"https://civitai.com/api/download/models/143906\",\n",
        "     \"filename\": \"EpiCRealism.safetensors\",    \"enabled\": True  },\n",
        "\n",
        "    {\"link\": \"https://civitai.com/api/download/models/901206?type=Model&format=SafeTensor&size=full&fp=fp16\",\n",
        "     \"filename\": \"Poetry Dream tassel.safetensors\",    \"enabled\": False  },\n",
        "\n",
        "    {\"link\": \"https://civitai.com/api/download/model_link_4\",\n",
        "     \"filename\": \"model4\",    \"enabled\": False  }\n",
        "\n",
        "\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "# ----------------------------------------\n",
        "# Token Section (define them here and create headers below)\n",
        "huggingface_token = \"your_huggingface_token\"\n",
        "civitai_api_key = \"your_civitai_token\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Now, after tokens are defined, create the headers\n",
        "huggingface_headers = {\n",
        "    \"Authorization\": f\"Bearer {huggingface_token}\"\n",
        "}\n",
        "civitai_headers = {\n",
        "    \"Authorization\": f\"Bearer {civitai_api_key}\"\n",
        "}\n",
        "\n",
        "# Call the combined download function\n",
        "download_models(model_list, huggingface_headers, civitai_headers)\n",
        "\n",
        "# Clear cache after downloads\n",
        "print(\"\\n\\nClearing cache...\\n\")\n",
        "subprocess.run([\"rm\", \"-rf\", \".cache\"])\n",
        "\n",
        "# Final storage check\n",
        "print(\"\\nAll downloads done!\")\n",
        "print(f\"Available space after downloading: {check_storage_space()}\\n\")\n"
      ],
      "metadata": {
        "id": "8g-5gJjaOPSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EMBEDDINGS"
      ],
      "metadata": {
        "id": "nVwhwcLuCizh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- EMBEDDINGS --- #\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/embed/negative/resolve/main/EasyNegative.pt -d /home/studio-lab-user/stable-diffusion-webui/embeddings/Negative -o EasyNegative.pt\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/gsdf/Counterfeit-V3.0/resolve/main/embedding/EasyNegativeV2.safetensors -d /home/studio-lab-user/stable-diffusion-webui/embeddings/Negative -o EasyNegativeV2.safetensors\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/embed/negative/resolve/main/bad-hands-5.pt -d /home/studio-lab-user/stable-diffusion-webui/embeddings/Negative -o bad-hands-5.pt\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/embed/negative/resolve/main/bad_prompt_version2.pt -d /home/studio-lab-user/stable-diffusion-webui/embeddings/Negative -o bad_prompt_version2.pt\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/embed/negative/resolve/main/ng_deepnegative_v1_75t.pt -d /home/studio-lab-user/stable-diffusion-webui/embeddings/Negative -o ng_deepnegative_v1_75t.pt\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ffxvs/negative-prompts-pack/resolve/main/bad-artist.pt -d /home/studio-lab-user/stable-diffusion-webui/embeddings/Negative -o bad-artist.pt\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ffxvs/negative-prompts-pack/resolve/main/badhandv4.pt -d /home/studio-lab-user/stable-diffusion-webui/embeddings/Negative -o badhandv4.pt\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ffxvs/negative-prompts-pack/resolve/main/verybadimagenegative_v1.3.pt -d /home/studio-lab-user/stable-diffusion-webui/embeddings/Negative -o verybadimagenegative_v1.3.pt\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://civitai.com/api/download/models/60938 -d /home/studio-lab-user/stable-diffusion-webui/embeddings/Negative -o negative_hand-neg.pt\n",
        "\n",
        "print('\u001b[1;32mDone!')"
      ],
      "metadata": {
        "id": "eddhtK_pCkuj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EXTENSIONS For Helping"
      ],
      "metadata": {
        "id": "E1vbB2IwCqKi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#--- EXTENSIONS --- #\n",
        "# !git clone https://github.com/deforum-art/deforum-for-automatic1111-webui /home/studio-lab-user/stable-diffusion-webui/extensions/deforum-for-automatic1111-webui\n",
        "#!git clone https://github.com/zanllp/sd-webui-infinite-image-browsing /home/studio-lab-user/stable-diffusion-webui/extensions/sd-webui-infinite-image-browsing\n",
        "!git clone https://github.com/etherealxx/batchlinks-webui /home/studio-lab-user/stable-diffusion-webui/extensions/batchlinks-webui\n",
        "#!git clone https://github.com/pkuliyi2015/multidiffusion-upscaler-for-automatic1111 /home/studio-lab-user/stable-diffusion-webui/extensions/multidiffusion-upscaler-for-automatic1111\n",
        "#!git clone https://github.com/mcmonkeyprojects/sd-dynamic-thresholding /home/studio-lab-userstable-diffusion-webui/extensions/sd-dynamic-thresholding\n",
        "!git clone https://github.com/DominikDoom/a1111-sd-webui-tagcomplete /home/studio-lab-user/stable-diffusion-webui/extensions/a1111-sd-webui-tagcomplete\n",
        "#!git clone https://github.com/aka7774/sd_filer /home/studio-lab-user/stable-diffusion-webui/extensions/sd_filer\n",
        "#!git clone https://github.com/hako-mikan/sd-webui-supermerger /home/studio-lab-user/stable-diffusion-webui/extensions/sd-webui-supermerger\n",
        "!git clone https://github.com/Bing-su/adetailer /home/studio-lab-user/stable-diffusion-webui/extensions/adetailer\n",
        "!git clone https://github.com/thomasasfk/sd-webui-aspect-ratio-helper /home/studio-lab-user/stable-diffusion-webui/extensions/sd-webui-aspect-ratio-helper\n",
        "#!git clone https://github.com/Elldreth/loopback_scaler /home/studio-lab-user/stable-diffusion-webui/extensions/loopback_scaler\n",
        "#!git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui-nsfw-censor /home/studio-lab-user/stable-diffusion-webui/extensions/stable-diffusion-webui-nsfw-censor\n",
        "#!git clone https://github.com/novitalabs/sd-webui-cleaner /home/studio-lab-user/stable-diffusion-webui/extensions/sd-webui-cleaner\n",
        "\n",
        "print('\u001b[1;32mDone!')\n"
      ],
      "metadata": {
        "id": "DLNQPAceCsDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# UI Config"
      ],
      "metadata": {
        "id": "ViKmu_VUC-yw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /home/studio-lab-user/stable-diffusion-webui/\n",
        "\n",
        "# - UI Config - #\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/TNitro/ui-config/resolve/main/ui-config.json -d /home/studio-lab-user/stable-diffusion-webui -o ui-config.json\n",
        "!sed -i -e 's/\\[\"sd_model_checkpoint\"\\],/\\[\"sd_model_checkpoint\",\"sd_vae\",\"CLIP_stop_at_last_layers\"\\],/g' /home/studio-lab-user/stable-diffusion-webui/modules/shared_options.py\n",
        "!sed -i -e 's/\"\\[seed\\]\"/\"\\[model_name\\],\\[seed\\]\"/g' /home/studio-lab-user/stable-diffusion-webui/modules/images.py\n",
        "!sed -i -e 's/\"CLIP_stop_at_last_layers\": OptionInfo(1,/\"CLIP_stop_at_last_layers\": OptionInfo(2,/g' /home/studio-lab-user/stable-diffusion-webui/modules/shared_options.py\n",
        "!sed -i -e 's/\"txt2img\\/Negative prompt\\/value\": \"\",/\"txt2img\\/Negative prompt\\/value\": \"(low quality, worst quality), EasyNegativeV2,\",/g' /home/studio-lab-user/stable-diffusion-webui/ui-config.json\n",
        "!sed -i -e 's/\"txt2img\\/Sampling method\\/value\": \"Euler a\",/\"txt2img\\/Sampling method\\/value\": \"DPM++ 2M SDE Karras\",/g' /home/studio-lab-user/stable-diffusion-webui/ui-config.json\n",
        "!sed -i -e 's/\"txt2img\\/Upscaler\\/value\": \"Latent\",/\"txt2img\\/Upscaler\\/value\": \"R-ESRGAN 4x+\",/g' /home/studio-lab-user/stable-diffusion-webui/ui-config.json\n",
        "!sed -i -e 's/\"gdown\"/\"aria2\"/g' /home/studio-lab-user/stable-diffusion-webui/extensions/batchlinks-webui/scripts/batchlinks-downloader.py\n",
        "print('\u001b[1;32mDone!')"
      ],
      "metadata": {
        "id": "ASRQqCkfDAG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LoRA (Optional)"
      ],
      "metadata": {
        "id": "E_aeRowA_bXK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import time\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "# Download path\n",
        "download_path = \"/home/studio-lab-user/stable-diffusion-webui/models/Lora/\"\n",
        "\n",
        "# Ensure the download path exists, create it if it doesn't\n",
        "os.makedirs(download_path, exist_ok=True)\n",
        "\n",
        "# Helper function to convert bytes into human-readable format\n",
        "def format_size(size):\n",
        "    for unit in ['B', 'KB', 'MB', 'GB', 'TB']:\n",
        "        if size < 1024:\n",
        "            return f\"{size:.2f} {unit}\"\n",
        "        size /= 1024\n",
        "\n",
        "# Function to check available storage space\n",
        "def check_storage_space():\n",
        "    result = subprocess.run([\"df\", \"-h\", \"--output=avail,target\"], capture_output=True, text=True)\n",
        "    lines = result.stdout.splitlines()\n",
        "\n",
        "    for line in lines:\n",
        "        if '/home' in line:\n",
        "            available_space = line.split()[0]  # Get available space value\n",
        "            return available_space\n",
        "    return \"0M\"  # Default value if no storage info available\n",
        "\n",
        "# Function to download model with reduced output frequency\n",
        "def download_model(url, filename, headers):\n",
        "    try:\n",
        "        # Automatically handle the file extension based on the filename provided\n",
        "        response = requests.get(url, headers=headers, stream=True)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            total_size = int(response.headers.get('content-length', 0))\n",
        "            downloaded_size = 0\n",
        "            start_time = time.time()\n",
        "\n",
        "            with open(filename, 'wb') as file:\n",
        "                chunk_size = 1024 * 1024  # Reduce the chunk size\n",
        "                for chunk in response.iter_content(chunk_size=chunk_size):\n",
        "                    if chunk:\n",
        "                        try:\n",
        "                            file.write(chunk)\n",
        "                            downloaded_size += len(chunk)\n",
        "\n",
        "                            if downloaded_size >= 10 * 1024 * 1024:  # Log progress every 10 MB\n",
        "                                elapsed_time = time.time() - start_time\n",
        "                                speed = (downloaded_size / (1024 * 1024)) / elapsed_time\n",
        "                                print(f\"Downloaded {format_size(downloaded_size)} of {format_size(total_size)} at {speed:.2f} MB/s\", end='\\r')\n",
        "                        except OSError as e:\n",
        "                            if \"No space left on device\" in str(e):\n",
        "                                print(f\"\\n\\nError: No space left on device while downloading {filename}.\")\n",
        "                                return \"no_space\"  # Return a specific message if no space\n",
        "                            raise\n",
        "            print(f\"\\n\\nDownloaded {filename} successfully!\\n\")\n",
        "            return \"success\"\n",
        "        else:\n",
        "            print(f\"\\n\\nFailed to download {filename}. Status code: {response.status_code}, Message: {response.text}\\n\")\n",
        "            return \"error\"\n",
        "    except Exception as e:\n",
        "        print(f\"\\n\\nError during download of {filename}: {e}\\n\")\n",
        "        if \"data exceeds\" in str(e).lower():\n",
        "            print(\"Error: Data exceeds Jupyter memory limit. Please download outside Jupyter Lab.\\n\")\n",
        "        return \"error\"\n",
        "\n",
        "# Combined function to handle both Hugging Face and CivitAI links\n",
        "def download_models(model_list, huggingface_headers, civitai_headers):\n",
        "    for model in model_list:\n",
        "        if model[\"enabled\"]:\n",
        "            url = model[\"link\"]\n",
        "            filename = os.path.join(download_path, model[\"filename\"])\n",
        "\n",
        "            # Identify if it's Hugging Face or CivitAI by checking the URL structure\n",
        "            if \"huggingface.co\" in url:\n",
        "                headers = huggingface_headers\n",
        "                platform = \"Hugging Face\"\n",
        "            elif \"civitai.com\" in url:\n",
        "                headers = civitai_headers\n",
        "                platform = \"CivitAI\"\n",
        "            else:\n",
        "                print(f\"\\n\\nUnknown platform for {filename}. Skipping...\\n\")\n",
        "                continue\n",
        "\n",
        "            print(f\"\\nStarting download from {platform} for {filename}...\\n\")\n",
        "\n",
        "            # Check storage before downloading\n",
        "            available_space = check_storage_space()\n",
        "            print(f\"Available space before downloading: {available_space}\\n\")\n",
        "\n",
        "            if available_space.endswith('G') or available_space.endswith('M'):\n",
        "                result = download_model(url, filename, headers)\n",
        "                if result == \"no_space\":\n",
        "                    print(f\"\\n\\nNo space available. Stopping remaining downloads.\\n\")\n",
        "                    break\n",
        "            else:\n",
        "                print(f\"\\n\\nNo space available for {filename}. Skipping...\\n\")\n",
        "        else:\n",
        "            print(f\"\\n\\nSkipping {model['filename']} (Disabled)\\n\")\n",
        "\n",
        "\n",
        "# ----------------------------------------\n",
        "# Example combined model inputs (both Hugging Face and CivitAI)\n",
        "model_list = [\n",
        "\n",
        "    {\"link\": \"https://civitai.com/api/download/models/103762?type=Model&format=SafeTensor\",\n",
        "     \"filename\": \"Oversized Clothing Collection.safetensors\",     \"enabled\": True  },\n",
        "\n",
        "    {\"link\": \"https://civitai.com/api/download/models/Lora\",\n",
        "     \"filename\": \"model2.safetensors\",    \"enabled\": False  },\n",
        "\n",
        "    {\"link\": \"https://civitai.com/api/download/model_link_3\",\n",
        "     \"filename\": \"model3.safetensors\",    \"enabled\": False  },\n",
        "\n",
        "    {\"link\": \"https://civitai.com/api/download/model_link_4\",\n",
        "     \"filename\": \"model4.safetensors\",    \"enabled\": False  }\n",
        "\n",
        "]\n",
        "\n",
        "# ----------------------------------------\n",
        "# Token Section (define them here and create headers below)\n",
        "huggingface_token = \"your_huggingface_token\"\n",
        "civitai_api_key = \"your_civitai_token\"\n",
        "\n",
        "# Now, after tokens are defined, create the headers\n",
        "huggingface_headers = {\n",
        "    \"Authorization\": f\"Bearer {huggingface_token}\"\n",
        "}\n",
        "civitai_headers = {\n",
        "    \"Authorization\": f\"Bearer {civitai_api_key}\"\n",
        "}\n",
        "\n",
        "# Call the combined download function\n",
        "download_models(model_list, huggingface_headers, civitai_headers)\n",
        "\n",
        "# Clear cache after downloads\n",
        "print(\"\\n\\nClearing cache...\\n\")\n",
        "subprocess.run([\"rm\", \"-rf\", \".cache\"])\n",
        "\n",
        "# Final storage check\n",
        "print(\"\\nAll downloads done!\")\n",
        "print(f\"Available space after downloading: {check_storage_space()}\\n\")\n"
      ],
      "metadata": {
        "id": "4W0nFuvQ8z_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VAE (Optional)"
      ],
      "metadata": {
        "id": "TRcIqiHcBdiJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import time\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "# Download path\n",
        "download_path = \"/home/studio-lab-user/stable-diffusion-webui/models/VAE/\"\n",
        "\n",
        "# Ensure the download path exists, create it if it doesn't\n",
        "os.makedirs(download_path, exist_ok=True)\n",
        "\n",
        "# Helper function to convert bytes into human-readable format\n",
        "def format_size(size):\n",
        "    for unit in ['B', 'KB', 'MB', 'GB', 'TB']:\n",
        "        if size < 1024:\n",
        "            return f\"{size:.2f} {unit}\"\n",
        "        size /= 1024\n",
        "\n",
        "# Function to check available storage space\n",
        "def check_storage_space():\n",
        "    result = subprocess.run([\"df\", \"-h\", \"--output=avail,target\"], capture_output=True, text=True)\n",
        "    lines = result.stdout.splitlines()\n",
        "\n",
        "    for line in lines:\n",
        "        if '/home' in line:\n",
        "            available_space = line.split()[0]  # Get available space value\n",
        "            return available_space\n",
        "    return \"0M\"  # Default value if no storage info available\n",
        "\n",
        "# Function to download model with reduced output frequency\n",
        "def download_model(url, filename, headers):\n",
        "    try:\n",
        "        # Automatically handle the file extension based on the filename provided\n",
        "        response = requests.get(url, headers=headers, stream=True)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            total_size = int(response.headers.get('content-length', 0))\n",
        "            downloaded_size = 0\n",
        "            start_time = time.time()\n",
        "\n",
        "            with open(filename, 'wb') as file:\n",
        "                chunk_size = 1024 * 1024  # Reduce the chunk size\n",
        "                for chunk in response.iter_content(chunk_size=chunk_size):\n",
        "                    if chunk:\n",
        "                        try:\n",
        "                            file.write(chunk)\n",
        "                            downloaded_size += len(chunk)\n",
        "\n",
        "                            if downloaded_size >= 10 * 1024 * 1024:  # Log progress every 10 MB\n",
        "                                elapsed_time = time.time() - start_time\n",
        "                                speed = (downloaded_size / (1024 * 1024)) / elapsed_time\n",
        "                                print(f\"Downloaded {format_size(downloaded_size)} of {format_size(total_size)} at {speed:.2f} MB/s\", end='\\r')\n",
        "                        except OSError as e:\n",
        "                            if \"No space left on device\" in str(e):\n",
        "                                print(f\"\\n\\nError: No space left on device while downloading {filename}.\")\n",
        "                                return \"no_space\"  # Return a specific message if no space\n",
        "                            raise\n",
        "            print(f\"\\n\\nDownloaded {filename} successfully!\\n\")\n",
        "            return \"success\"\n",
        "        else:\n",
        "            print(f\"\\n\\nFailed to download {filename}. Status code: {response.status_code}, Message: {response.text}\\n\")\n",
        "            return \"error\"\n",
        "    except Exception as e:\n",
        "        print(f\"\\n\\nError during download of {filename}: {e}\\n\")\n",
        "        if \"data exceeds\" in str(e).lower():\n",
        "            print(\"Error: Data exceeds Jupyter memory limit. Please download outside Jupyter Lab.\\n\")\n",
        "        return \"error\"\n",
        "\n",
        "# Combined function to handle both Hugging Face and CivitAI links\n",
        "def download_models(model_list, huggingface_headers, civitai_headers):\n",
        "    for model in model_list:\n",
        "        if model[\"enabled\"]:\n",
        "            url = model[\"link\"]\n",
        "            filename = os.path.join(download_path, model[\"filename\"])\n",
        "\n",
        "            # Identify if it's Hugging Face or CivitAI by checking the URL structure\n",
        "            if \"huggingface.co\" in url:\n",
        "                headers = huggingface_headers\n",
        "                platform = \"Hugging Face\"\n",
        "            elif \"civitai.com\" in url:\n",
        "                headers = civitai_headers\n",
        "                platform = \"CivitAI\"\n",
        "            else:\n",
        "                print(f\"\\n\\nUnknown platform for {filename}. Skipping...\\n\")\n",
        "                continue\n",
        "\n",
        "            print(f\"\\nStarting download from {platform} for {filename}...\\n\")\n",
        "\n",
        "            # Check storage before downloading\n",
        "            available_space = check_storage_space()\n",
        "            print(f\"Available space before downloading: {available_space}\\n\")\n",
        "\n",
        "            if available_space.endswith('G') or available_space.endswith('M'):\n",
        "                result = download_model(url, filename, headers)\n",
        "                if result == \"no_space\":\n",
        "                    print(f\"\\n\\nNo space available. Stopping remaining downloads.\\n\")\n",
        "                    break\n",
        "            else:\n",
        "                print(f\"\\n\\nNo space available for {filename}. Skipping...\\n\")\n",
        "        else:\n",
        "            print(f\"\\n\\nSkipping {model['filename']} (Disabled)\\n\")\n",
        "\n",
        "\n",
        "# ----------------------------------------\n",
        "# Example combined model inputs (both Hugging Face and CivitAI)\n",
        "model_list = [\n",
        "\n",
        "    {\"link\": \"https://civitai.com/api/download/models/28569?type=Model&format=SafeTensor\",\n",
        "     \"filename\": \"kl-f8-anime2 VAE.safetensors\",     \"enabled\": True  },\n",
        "\n",
        "    {\"link\": \"https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.safetensors\",\n",
        "     \"filename\": \"vae-ft-mse-840000-ema-pruned.safetensors\",    \"enabled\": True  },\n",
        "\n",
        "    {\"link\": \"https://civitai.com/api/download/model_link_3\",\n",
        "     \"filename\": \"model3.safetensors\",    \"enabled\": False  },\n",
        "\n",
        "    {\"link\": \"https://civitai.com/api/download/model_link_4\",\n",
        "     \"filename\": \"model4.safetensors\",    \"enabled\": False  }\n",
        "\n",
        "]\n",
        "\n",
        "# ----------------------------------------\n",
        "# Token Section (define them here and create headers below)\n",
        "huggingface_token = \"your_huggingface_token\"\n",
        "civitai_api_key = \"your_civitai_token\"\n",
        "\n",
        "# Now, after tokens are defined, create the headers\n",
        "huggingface_headers = {\n",
        "    \"Authorization\": f\"Bearer {huggingface_token}\"\n",
        "}\n",
        "civitai_headers = {\n",
        "    \"Authorization\": f\"Bearer {civitai_api_key}\"\n",
        "}\n",
        "\n",
        "# Call the combined download function\n",
        "download_models(model_list, huggingface_headers, civitai_headers)\n",
        "\n",
        "# Clear cache after downloads\n",
        "print(\"\\n\\nClearing cache...\\n\")\n",
        "subprocess.run([\"rm\", \"-rf\", \".cache\"])\n",
        "\n",
        "# Final storage check\n",
        "print(\"\\nAll downloads done!\")\n",
        "print(f\"Available space after downloading: {check_storage_space()}\\n\")\n"
      ],
      "metadata": {
        "id": "zmt4FqiQ9y5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Controal-Net extensions + Controal-Net-Models"
      ],
      "metadata": {
        "id": "0sVXBVpMBzte"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Control-Net Extension#\n",
        "\n",
        "!git clone https://github.com/Mikubill/sd-webui-controlnet /home/studio-lab-user/stable-diffusion-webui/extensions/sd-webui-controlnet\n",
        "\n",
        "\n",
        "#Control-Net Models#\n",
        "\n",
        "# !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11e_sd15_ip2p_fp16.safetensors -d /home/studio-lab-user/stable-diffusion-webui/extensions/sd-webui-controlnet/models -o control_v11e_sd15_ip2p_fp16.safetensors\n",
        "# !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11e_sd15_shuffle_fp16.safetensors -d /home/studio-lab-user/stable-diffusion-webui/extensions/sd-webui-controlnet/models -o control_v11e_sd15_shuffle_fp16.safetensors\n",
        "# !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_canny_fp16.safetensors -d /home/studio-lab-user/stable-diffusion-webui/extensions/sd-webui-controlnet/models -o control_v11p_sd15_canny_fp16.safetensors\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_depth_fp16.safetensors -d /home/studio-lab-user/stable-diffusion-webui/extensions/sd-webui-controlnet/models -o control_v11p_sd15_depth_fp16.safetensors\n",
        "# !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_inpaint_fp16.safetensors -d /home/studio-lab-user/stable-diffusion-webui/extensions/sd-webui-controlnet/models -o control_v11p_sd15_inpaint_fp16.safetensors\n",
        "# !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_lineart_fp16.safetensors -d /home/studio-lab-user/stable-diffusion-webui/extensions/sd-webui-controlnet/models -o control_v11p_sd15_lineart_fp16.safetensors\n",
        "# !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_mlsd_fp16.safetensors -d /home/studio-lab-user/stable-diffusion-webui/extensions/sd-webui-controlnet/models -o control_v11p_sd15_mlsd_fp16.safetensors\n",
        "# !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_normalbae_fp16.safetensors -d /home/studio-lab-user/stable-diffusion-webui/extensions/sd-webui-controlnet/models -o control_v11p_sd15_normalbae_fp16.safetensors\n",
        "# !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_openpose_fp16.safetensors -d /home/studio-lab-user/stable-diffusion-webui/extensions/sd-webui-controlnet/models -o control_v11p_sd15_openpose_fp16.safetensors\n",
        "# !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_scribble_fp16.safetensors -d /home/studio-lab-user/stable-diffusion-webui/extensions/sd-webui-controlnet/models -o control_v11p_sd15_scribble_fp16.safetensors\n",
        "# !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_seg_fp16.safetensors -d /home/studio-lab-user/stable-diffusion-webui/extensions/sd-webui-controlnet/models -o control_v11p_sd15_seg_fp16.safetensors\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_softedge_fp16.safetensors -d /home/studio-lab-user/stable-diffusion-webui/extensions/sd-webui-controlnet/models -o control_v11p_sd15_softedge_fp16.safetensors\n",
        "# !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15s2_lineart_anime_fp16.safetensors -d /home/studio-lab-user/stable-diffusion-webui/extensions/sd-webui-controlnet/models -o control_v11p_sd15s2_lineart_anime_fp16.safetensors\n",
        "# !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11u_sd15_tile_fp16.safetensors -d /home/studio-lab-user/stable-diffusion-webui/extensions/sd-webui-controlnet/models -o control_v11u_sd15_tile_fp16.safetensors\n",
        "# !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/t2iadapter_style_sd14v1.pth -d /home/studio-lab-user/stable-diffusion-webui/extensions/sd-webui-controlnet/models -o t2iadapter_style_sd14v1.pth\n",
        "# !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/t2iadapter_sketch_sd14v1.pth -d /home/studio-lab-user/stable-diffusion-webui/extensions/sd-webui-controlnet/models -o t2iadapter_sketch_sd14v1.pth\n",
        "# !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/t2iadapter_seg_sd14v1.pth -d /home/studio-lab-user/stable-diffusion-webui/extensions/sd-webui-controlnet/models -o t2iadapter_seg_sd14v1.pth\n",
        "# !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/t2iadapter_openpose_sd14v1.pth -d /home/studio-lab-user/stable-diffusion-webui/extensions/sd-webui-controlnet/models -o t2iadapter_openpose_sd14v1.pth\n",
        "# !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/t2iadapter_keypose_sd14v1.pth -d /home/studio-lab-user/stable-diffusion-webui/extensions/sd-webui-controlnet/models -o t2iadapter_keypose_sd14v1.pth\n",
        "# !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/t2iadapter_color_sd14v1.pth -d /home/studio-lab-user/stable-diffusion-webui/extensions/sd-webui-controlnet/models -o t2iadapter_color_sd14v1.pth\n",
        "# !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/t2iadapter_canny_sd15v2.pth -d /home/studio-lab-user/stable-diffusion-webui/extensions/sd-webui-controlnet/models -o t2iadapter_canny_sd15v2.pth\n",
        "# !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/t2iadapter_depth_sd15v2.pth -d /home/studio-lab-user/stable-diffusion-webui/extensions/sd-webui-controlnet/models -o t2iadapter_depth_sd15v2.pth\n",
        "# !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/t2iadapter_sketch_sd15v2.pth -d /home/studio-lab-user/stable-diffusion-webui/extensions/sd-webui-controlnet/models -o t2iadapter_sketch_sd15v2.pth\n",
        "# !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/t2iadapter_zoedepth_sd15v1.pth -d /home/studio-lab-user/stable-diffusion-webui/extensions/sd-webui-controlnet/models -o t2iadapter_zoedepth_sd15v1.pth\n",
        "# !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/monster-labs/control_v1p_sd15_qrcode_monster/resolve/main/control_v1p_sd15_qrcode_monster.safetensors -d /home/studio-lab-user/stable-diffusion-webui/extensions/sd-webui-controlnet/models -o control_v1p_sd15_qrcode_monster.safetensors\n",
        "# !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/monster-labs/control_v1p_sd15_qrcode_monster/resolve/main/v2/control_v1p_sd15_qrcode_monster_v2.safetensors -d /home/studio-lab-user/stable-diffusion-webui/extensions/sd-webui-controlnet/models -o control_v1p_sd15_qrcode_monster_v2.safetensors\n",
        "\n",
        "print('\u001b[1;32mDone!')\n",
        "\n",
        "!rm -rf /home/studio-lab-user/.cache\n",
        "!df -h | grep -E 'Avail|home'\n",
        "\n",
        "print('\u001b[1;32mDone!')"
      ],
      "metadata": {
        "id": "7IiXw6LyB2qW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Launch Stable-Diffusion WebUi"
      ],
      "metadata": {
        "id": "R9kbPdGlCXmS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ~/stable-diffusion-webui\n",
        "\n",
        "!python launch.py --listen --xformers --enable-insecure-extension-access --gradio-queue --ngrok 2XWKyblB2vN0oonn4F9owPN1gfL_4wZ4rxXdb8sPqsdfgW"
      ],
      "metadata": {
        "id": "D9H6oupiCZcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Storage Check"
      ],
      "metadata": {
        "id": "J2v6umQsAY02"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Check the storage available\n",
        "!df -h | grep -E 'Avail|home'\n",
        "\n",
        "print('\u001b[1;32mDone!')"
      ],
      "metadata": {
        "id": "7w4tzwAqAeIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clean Everythings"
      ],
      "metadata": {
        "id": "hbC8fvM2Faik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "!rm -r /home/studio-lab-user/.cache\n",
        "!rm -r /home/studio-lab-user/.conda\n",
        "!conda clean --all\n",
        "!rm -rf /home/studio-lab-user/*\n",
        "clear_output()\n",
        "!df -h | grep -E 'Avail|home'\n",
        "print('\u001b[1;32mDone!')"
      ],
      "metadata": {
        "id": "AjWvcfaJFiye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!du -h --max-depth=1 /home/studio-lab-user"
      ],
      "metadata": {
        "id": "12XbT5M7AJKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Remove all installed packages\n",
        "!conda remove --all -y\n",
        "\n",
        "# Step 2: Clear cached packages\n",
        "!conda clean --all -y\n",
        "\n",
        "# Step 3: Restart kernel\n",
        "from IPython.display import display, Javascript\n",
        "display(Javascript('Jupyter.notebook.restart_kernel()'))\n",
        "\n",
        "# Step 4: After restart, check available packages (this will run after restart)\n",
        "!conda list\n"
      ],
      "metadata": {
        "id": "N5M98vTJJjjL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "vxYteB9nSX3-",
        "76xxmC9HKdms",
        "lzzY6lQRKxRt",
        "eyQ0usVMNKj8",
        "D3FPHTicN93T",
        "nVwhwcLuCizh",
        "E1vbB2IwCqKi",
        "ViKmu_VUC-yw",
        "E_aeRowA_bXK",
        "TRcIqiHcBdiJ",
        "0sVXBVpMBzte",
        "R9kbPdGlCXmS",
        "J2v6umQsAY02",
        "hbC8fvM2Faik"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}